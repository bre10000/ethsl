{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "South\n",
      "East\n",
      "North\n"
     ]
    }
   ],
   "source": [
    "from PyQt5.QtGui import *\n",
    "from PyQt5.QtWidgets import *\n",
    "from PyQt5.QtCore import *\n",
    "from PyQt5 import QtWidgets\n",
    "from PyQt5 import QtGui\n",
    "from PyQt5 import QtCore, QtGui, QtWidgets\n",
    "from collections import deque\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import cv2\n",
    "import imutils\n",
    "from collections import Counter\n",
    "counter = 0\n",
    "buffer = 32\n",
    "pts = deque(maxlen=buffer)\n",
    "D = []\n",
    "(dX,dY) = (0,0)\n",
    "direction = \"\"\n",
    "center =\"None\"\n",
    "\n",
    "# Disable tensorflow compilation warnings\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']='2'\n",
    "import tensorflow as tf\n",
    "\n",
    "def Track (hsv, frame):\n",
    "    \n",
    "    \n",
    "    lower= np.array([0,48,80], dtype=\"uint8\")\n",
    "    upper = np.array([20,255,255], dtype=\"uint8\")\n",
    "# initialize the list of tracked point, the frame counter.the cordinates\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    mask = cv2.inRange(hsv, lower,upper)\n",
    "    mask = cv2.erode(mask, None, iterations = 2)\n",
    "    mask = cv2.dilate(mask,None,iterations = 2)\n",
    "    \n",
    "    \n",
    "    cnts = cv2.findContours(mask.copy(), cv2.RETR_EXTERNAL,\n",
    "                            cv2.CHAIN_APPROX_SIMPLE)[-2]\n",
    "    center = \"None\"\n",
    "    \n",
    "    if len(cnts) > 0:\n",
    "            \n",
    "            c= max(cnts, key=cv2.contourArea)\n",
    "            ((x,y), radius) = cv2.minEnclosingCircle(c)\n",
    "            M = cv2.moments(c)\n",
    "            center = (int(M[\"m10\"] / M[\"m00\"]), int(M[\"m01\"] / M[\"m00\"]))\n",
    "            \n",
    "            \n",
    "            if radius > 10:\n",
    "                cv2.circle(frame, (int(x), int(y)), int(radius), (0,255,255),2 )\n",
    "                cv2.circle(frame, center, 5, (0,0,255), -1)\n",
    "                pts.appendleft(center)\n",
    "                \n",
    "            \n",
    "            \n",
    "            for i in np.arange(1,len(pts)):\n",
    "                if pts[i - 1] is None or pts[i] is None:\n",
    "                    \n",
    "                    continue\n",
    "                   \n",
    "                global counter\n",
    "                global direction\n",
    "                global dX,dY,D\n",
    "                \n",
    "                if counter >= 10 and i == 10  and pts[i-10] is not None :\n",
    "                    \n",
    "                    \n",
    "                    dX = pts[i-10][0] - pts [i][0]\n",
    "                    dY = pts[i-10][1] - pts [i][1]\n",
    "                    (dirX, dirY) = (\"\",\"\")\n",
    "                    \n",
    "    \n",
    "                    \n",
    "                    if np.abs(dX)> 10 :\n",
    "                        \n",
    "                        dirX= \"East\" if np.sign(dX) == 1 else \"West\"\n",
    "                        D.append(dirX)\n",
    "                    if np.abs(dY) > 10 :\n",
    "                        dirY= \"North\" if np.sign(dY) == 1 else \"South\"\n",
    "                        D.append(dirY)\n",
    "                    if dirX !=\"\" and dirY !=\"\":\n",
    "                        direction = \"{}-{}\".format(dirY,dirX)\n",
    "                        D.append(direction)\n",
    "                    else:\n",
    "                        direction  = dirX if dirX !=\"\" else dirY\n",
    "                        D.append(direction)\n",
    "                \n",
    "                thicknees = 2\n",
    "                counter +=1  \n",
    "                cv2.line(frame, pts[i-1], pts[i], (0,0,255), thicknees)\n",
    "                \n",
    "                \n",
    "                 \n",
    "            \n",
    "def predict(image_data):\n",
    "\n",
    "    predictions = sess.run(softmax_tensor, \\\n",
    "             {'DecodeJpeg/contents:0': image_data})\n",
    "\n",
    "    # Sort to show labels of first prediction in order of confidence\n",
    "    top_k = predictions[0].argsort()[-len(predictions[0]):][::-1]\n",
    "\n",
    "    max_score = 0.0\n",
    "    res = ''\n",
    "    for node_id in top_k:\n",
    "        human_string = label_lines[node_id]\n",
    "        score = predictions[0][node_id]\n",
    "        if score > max_score:\n",
    "            max_score = score\n",
    "            res = human_string\n",
    "    return res, max_score\n",
    "\n",
    "# Loads label file, strips off carriage return\n",
    "label_lines = [line.rstrip() for line\n",
    "                   in tf.gfile.GFile(\"logs/trained_labels.txt\")]\n",
    "\n",
    "# Unpersists graph from file\n",
    "with tf.gfile.FastGFile(\"logs/trained_graph.pb\", 'rb') as f:\n",
    "    graph_def = tf.GraphDef()\n",
    "    graph_def.ParseFromString(f.read())\n",
    "    _ = tf.import_graph_def(graph_def, name='')\n",
    "\n",
    "    \n",
    "x = None\n",
    "text = \"\"\n",
    "norec = False\n",
    "with tf.Session() as sess:  \n",
    "    \n",
    "    def getVowel(x,direction):\n",
    "        amharic_letters = [[\"ሀ\",\"ሁ\",\"ሂ\",\"ሃ\",\"ሄ\",\"ህ\",\"ሆ\"],[\"ለ\",\"ሉ\",\"ሊ\",\"ላ\",\"ሌ\",\"ል\",\"ሎ\"],[\"ሐ\",\"ሑ\",\"ሒ\",\"ሓ\",\"ሔ\",\"ሕ\",\"ሖ\"],[\"መ\",\"ሙ\",\"ሚ\",\"ማ\",\"ሜ\",\"ም\",\"ሞ\"]]\n",
    "        if (direction==\"East\"):\n",
    "            return amharic_letters[x-1][1]\n",
    "        elif(direction==\"West\"):\n",
    "            return amharic_letters[x-1][2]\n",
    "        elif(direction==\"North\"):\n",
    "            return amharic_letters[x-1][3]\n",
    "        elif(direction==\"South\"):\n",
    "            return amharic_letters[x-1][4]\n",
    "        elif(direction==\"South-West\" or direction==\"South-East\"):\n",
    "            return amharic_letters[x-1][5]\n",
    "        elif(direction==\"North-West\" or direction==\"North-East\"):\n",
    "            return amharic_letters[x-1][6]\n",
    "        elif(direction==\"\"):\n",
    "            return amharic_letters[x-1][0]\n",
    "        else:\n",
    "            return \"\"\n",
    "        \n",
    "    def getLetter(x):\n",
    "        amharic_letters = [\"ሀ\",\"ለ\",\"ሐ\",\"መ\"]\n",
    "        return amharic_letters[x-1]\n",
    "\n",
    "    softmax_tensor = sess.graph.get_tensor_by_name('final_result:0')\n",
    "    class Thread(QThread):\n",
    "        changePixmap = pyqtSignal(QImage)\n",
    "        \n",
    "        def run(self):\n",
    "            # Feed the image_data as input to the graph and get first prediction\n",
    "\n",
    "            c = 0\n",
    "\n",
    "            cap = cv2.VideoCapture(0)\n",
    "\n",
    "            res, score = '', 0.0\n",
    "            i = 0\n",
    "            mem = ''\n",
    "            consecutive = 0\n",
    "            sequence = ''\n",
    "            \n",
    "            \n",
    "            while True:\n",
    "                ret, frame = cap.read()\n",
    "                frame=cv2.flip(frame,1)\n",
    "                x1,y1,x2,y2 = 150,150,350,350\n",
    "                img_cropped= frame[y1:y2, x1:x2]\n",
    "                global D\n",
    "                global norec\n",
    "                c += 1\n",
    "                image_data = cv2.imencode('.jpg', img_cropped)[1].tostring()\n",
    "                cv2.rectangle(frame,(x1,y1), (x2,y2), (255,0,0),2 )\n",
    "                rgbImage = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                convertToQtFormat = QImage(rgbImage.data, rgbImage.shape[1], rgbImage.shape[0], QImage.Format_RGB888)\n",
    "                p = convertToQtFormat.scaled(640, 480, Qt.KeepAspectRatio)\n",
    "                self.changePixmap.emit(p)\n",
    "                \n",
    "                #tensor\n",
    "                res_tmp, score = predict(image_data)\n",
    "                \n",
    "                #print(score)\n",
    "                res = res_tmp\n",
    "                i = 0\n",
    "                if i == 4:\n",
    "                    if mem == res:\n",
    "                        consecutive += 1\n",
    "                    else:\n",
    "                        consecutive = 0\n",
    "                    if consecutive == 2 and res not in ['nothing']:\n",
    "                        if res == 'space':\n",
    "                            sequence += ' '\n",
    "                            print(\"C\")\n",
    "                        elif res == 'del':\n",
    "                            sequence = sequence[:-1]\n",
    "                            print(\"B\")\n",
    "                        else:\n",
    "                            sequence += res\n",
    "                            print(\"A\")\n",
    "                        consecutive = 0\n",
    "                i+=1\n",
    "                global text\n",
    "                if (res.upper()==\"NOTHING\"):\n",
    "                    text+=\"\"\n",
    "                    norec = False\n",
    "                elif (norec):\n",
    "                    continue\n",
    "                elif (res.upper()==\"SPACE\"):\n",
    "                    text+=\" \"\n",
    "                elif (res.upper()==\"DEL\"):\n",
    "                    text= text[0:-2]\n",
    "                else:\n",
    "                    for i in range(0,20):\n",
    "                        (grabbed,img) = cap.read()\n",
    "                        img=cv2.flip(img,1)\n",
    "                        img = imutils.resize(img, width=600)\n",
    "                        x1,y1,x2,y2 = 100,100,400,400\n",
    "                        cv2.rectangle(img,(x1,y1), (x2,y2), (255,0,0),2 )\n",
    "                        x11,y11,x22,y22 = 200,300,200,300\n",
    "                        cv2.rectangle(img,(x11,y11), (x22,y22), (255,0,0),2 )\n",
    "                        frame= img[y1:y2, x1:x2]\n",
    "                        blurred = cv2.GaussianBlur(frame,(11,11),0)\n",
    "                        hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "                        Track(hsv,frame)\n",
    "                        cv2.putText(img, direction,(10,30), cv2.FONT_HERSHEY_SIMPLEX,0.65,(0,0,255),3)\n",
    "                        cv2.putText(img, \"dX: {},dY: {}\".format(dX,dY), (10, frame.shape[0]-10),cv2.FONT_HERSHEY_SIMPLEX,0.35,(0,255,255),1)\n",
    "                        rgbImage = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                        convertToQtFormat = QImage(rgbImage.data, rgbImage.shape[1], rgbImage.shape[0], QImage.Format_RGB888)\n",
    "                        p = convertToQtFormat.scaled(640, 480, Qt.KeepAspectRatio)\n",
    "                        self.changePixmap.emit(p)\n",
    "                        \n",
    "                    norec = True\n",
    "                    \n",
    "                    if D == []:\n",
    "                        text += getLetter(int(res.upper()))\n",
    "                        \n",
    "                    else:\n",
    "                        value  = Counter(D).most_common(1)[0][0]\n",
    "                        print(value)\n",
    "                        text += getVowel(int(res.upper()), value)\n",
    "                \n",
    "                D =[]\n",
    "                global x\n",
    "                pts.clear()\n",
    "                x.setText(text)\n",
    "                \n",
    "                \n",
    "\n",
    "    class App(QWidget):\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "            self.title = 'Eth SL'\n",
    "            self.left = 100\n",
    "            self.top = 100\n",
    "            self.width = 640\n",
    "            self.height = 480\n",
    "\n",
    "            self.initUI()\n",
    "\n",
    "        @pyqtSlot(QImage)\n",
    "        def setImage(self, image):\n",
    "            self.label.setPixmap(QPixmap.fromImage(image))\n",
    "        def initUI(self):\n",
    "            self.setWindowTitle(self.title)\n",
    "            self.setWindowIcon(QtGui.QIcon('logo.png'))\n",
    "            self.setGeometry(self.left, self.top, self.width, self.height)\n",
    "            self.resize(1000, 550)\n",
    "            # create a label\n",
    "            self.hsv_title = QLabel(self)\n",
    "            self.hsv_title.move(650, 10)\n",
    "            font = QtGui.QFont(\"Roboto\", 32, QtGui.QFont.Bold)\n",
    "            self.hsv_title.setFont(font)\n",
    "            self.hsvti\n",
    "            self.label.resize(640, 480)\n",
    "            self.le = QLineEdit(self)\n",
    "            self.le.move(0, 480)\n",
    "            #font = self.le.font()      # lineedit current font\n",
    "            #font.setPointSize(32)  # change it's size\n",
    "            palette = QtGui.QPalette()\n",
    "            palette.setColor(QtGui.QPalette.Text, QtCore.Qt.red)\n",
    "            self.le.setPalette(palette)\n",
    "            font = QtGui.QFont(\"Noto Sans Ethiopic\", 32, QtGui.QFont.Bold)\n",
    "            self.le.setFont(font)      # set font\n",
    "            self.le.resize(640,70)\n",
    "            global x\n",
    "            x = self.le\n",
    "            #self.le.setText(getVowel(1,\"east\"))\n",
    "            self.show()\n",
    "            th = Thread(self)\n",
    "            th.changePixmap.connect(self.setImage)\n",
    "            th.start()\n",
    "    if __name__ == '__main__':\n",
    "        app = QtWidgets.QApplication(sys.argv)\n",
    "        app.setStyle('Fusion')\n",
    "        palette = QtGui.QPalette()\n",
    "        palette.setColor(QtGui.QPalette.Window, QtGui.QColor(53,53,53))\n",
    "        palette.setColor(QtGui.QPalette.WindowText, QtCore.Qt.white)\n",
    "        palette.setColor(QtGui.QPalette.Base, QtGui.QColor(15,15,15))\n",
    "        palette.setColor(QtGui.QPalette.AlternateBase, QtGui.QColor(53,53,53))\n",
    "        palette.setColor(QtGui.QPalette.ToolTipBase, QtCore.Qt.white)\n",
    "        palette.setColor(QtGui.QPalette.ToolTipText, QtCore.Qt.white)\n",
    "        palette.setColor(QtGui.QPalette.Text, QtCore.Qt.white)\n",
    "        palette.setColor(QtGui.QPalette.Button, QtGui.QColor(53,53,53))\n",
    "        palette.setColor(QtGui.QPalette.ButtonText, QtCore.Qt.white)\n",
    "        palette.setColor(QtGui.QPalette.BrightText, QtCore.Qt.red)\n",
    "\n",
    "        palette.setColor(QtGui.QPalette.Highlight, QtGui.QColor(0,116,255).lighter())\n",
    "        palette.setColor(QtGui.QPalette.HighlightedText, QtCore.Qt.black)\n",
    "        app.setPalette(palette)\n",
    "        ex = App()\n",
    "        exit(app.exec())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
